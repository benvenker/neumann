{"id":"nm-1","title":"Implement Code Review Changes","description":"Implement all recommendations from the GPT-5 Pro code review to align the codebase with a pages-first philosophy and fix quality issues. This includes changing defaults from \"both pages and tiles\" to \"pages only\", fixing resource leaks with context managers, improving grid tiler edge coverage, tightening CSS styling, updating tests, and lowering Python version requirement to 3.10 for better AI package compatibility.\n\nKey Changes:\n- Make pages-only the default (emit=pages, manifest=none)\n- Fix resource leaks in PDF and image handling\n- Improve grid tiler to guarantee edge coverage\n- Tighten line-number gutter CSS styling\n- Update all documentation to reflect new defaults\n- Add comprehensive tests for default behavior\n- Lower Python requirement from 3.13 to 3.10","status":"closed","priority":2,"issue_type":"epic","assignee":"ProductThor","created_at":"2025-10-29T20:39:25.299684-05:00","updated_at":"2025-10-29T21:17:40.958777-05:00","closed_at":"2025-10-29T21:17:40.958777-05:00"}
{"id":"nm-10","title":"Fix Grid Tiler Edge Coverage","description":"Replace the current grid tiler implementation to guarantee complete edge coverage. The current implementation risks missing content at the right and bottom edges of images. The new implementation must generate coordinate lists that ensure the final tile covers the rightmost and bottommost edges, with proper clamping to prevent out-of-bounds access.\n\nImplementation Details:\n- Replace `tile_grid()` function (lines 266-281) with improved version\n- Generate x/y coordinate lists ensuring right/bottom edges are covered\n- Handle edge case where last tile would extend beyond image bounds\n- Use `min()` to clamp crops and prevent out-of-bounds access\n- Ensure all image content is included in tiles, even near edges","status":"in_progress","priority":2,"issue_type":"task","assignee":"ProductThor","created_at":"2025-10-29T21:10:46.961075-05:00","updated_at":"2025-10-29T21:10:46.961075-05:00"}
{"id":"nm-11","title":"Update Documentation","description":"Update both README.md and docs/IMPLEMENTATION_PLAN.md to accurately reflect the new pages-only default behavior. Update examples, option descriptions, output structure documentation, and design decision rationale to align with the pages-first philosophy.\n\nImplementation Details:\n- **README.md**:\n  - Update description to emphasize pages-first, tiles optional (line 3)\n  - Update \"Basic Example\" section to show pages-only default (lines 54-60)\n  - Add separate section for tiles showing it as optional (lines 62-78)\n  - Update `--emit` and `--manifest` defaults in options list (lines 95-96)\n  - Update output structure section to show pages-only default (lines 99-114)\n  - Add note about line-number styling\n- **docs/IMPLEMENTATION_PLAN.md**:\n  - Update \"Default Behavior\" section (lines 9-12): pages-only, manifest=none\n  - Update CLI examples to reflect new defaults (lines 63-77, 99-100)\n  - Update \"Design Decisions\" section to explain pages-first rationale (lines 179-183)","status":"in_progress","priority":2,"issue_type":"task","assignee":"ProductThor","created_at":"2025-10-29T21:16:47.039499-05:00","updated_at":"2025-10-29T21:16:47.039499-05:00"}
{"id":"nm-12","title":"Create Configuration Module","description":"Create config.py with Pydantic models for type-safe configuration management. Load settings from environment variables with sensible defaults.\n\nImplementation Details:\n- Use Pydantic BaseSettings for automatic env loading\n- Fields: ASSET_BASE_URL, CHROMA_PATH, OPENAI_API_KEY, LINES_PER_CHUNK, OVERLAP\n- Validation: ensure URLs are well-formed, paths exist, API key is present\n- Export a singleton `config` instance for import by other modules\n\nTesting:\n- Unit test: test_config_loads_defaults\n- Unit test: test_config_loads_from_env\n- Unit test: test_config_validation_fails_on_missing_api_key\n\nAcceptance:\n- config.py imports cleanly\n- All settings accessible via `from config import config`\n- .env.example provided with sample values\n- Type hints pass mypy checks","notes":"Labels: component:config, phase:foundation, tech:pydantic","status":"in_progress","priority":1,"issue_type":"task","created_at":"2025-10-29T22:45:15.775714-05:00","updated_at":"2025-10-29T22:50:39.179287-05:00","labels":["component:config","phase:foundation","tech:pydantic"]}
{"id":"nm-13","title":"Add Dependencies to pyproject.toml","description":"Add required dependencies for MVP: chromadb, openai, pyyaml, python-dotenv, pydantic-settings. Update pyproject.toml and lock file.\n\nDependencies to Add:\n- chromadb\u003e=0.4.0\n- openai\u003e=1.0.0\n- pyyaml\u003e=6.0\n- python-dotenv\u003e=1.0.0\n- pydantic\u003e=2.0\n- pydantic-settings\u003e=2.0\n\nTesting:\n- Verify all packages install: `uv pip install -e \".[dev]\"`\n- Verify imports work: `python -c \"import chromadb; import openai\"`\n\nAcceptance:\n- All dependencies in pyproject.toml\n- uv.lock updated\n- Dependencies install without conflicts\n- Import smoke test passes","notes":"Labels: component:config, phase:foundation","status":"closed","priority":1,"issue_type":"task","assignee":"ProductThor","created_at":"2025-10-29T22:45:20.668563-05:00","updated_at":"2025-10-29T23:40:05.372476-05:00","closed_at":"2025-10-29T23:40:05.372476-05:00","labels":["component:config","phase:foundation"]}
{"id":"nm-14","title":"Add URI Generation to Renderer","description":"Modify render_to_webp.py to generate HTTP URIs for each page WebP using the ASSET_BASE_URL from config. Update the manifest generation to include the `uri` field.\n\nImplementation Details:\n- Import `config` from config module\n- In pdf_to_webp_pages(), build URI for each page:\n  - Format: {ASSET_BASE_URL}/out/{doc_id}/pages/{filename}\n  - Example: http://127.0.0.1:8000/out/src__auth__module.ts/pages/src__auth__module-p001.webp\n- Pass URIs through to manifest generation\n- Update manifest dict to include `uri` field\n\nReference: main-spec.md §3.1 (Pages manifest example)\n\nTesting:\n- Unit test: test_uri_generation_format\n- Integration test: render a file and verify URI in pages.jsonl\n- Manual test: verify URI is accessible via http.server\n\nAcceptance:\n- pages.jsonl contains `uri` field for every page\n- URIs are well-formed and resolvable\n- Backward compatible with existing manifest fields","notes":"Labels: component:rendering, phase:foundation","status":"closed","priority":1,"issue_type":"feature","assignee":"ProductThor","created_at":"2025-10-29T22:45:28.3968-05:00","updated_at":"2025-10-30T09:12:43.053473-05:00","closed_at":"2025-10-30T09:12:43.053473-05:00","labels":["component:rendering","phase:foundation"],"dependencies":[{"issue_id":"nm-14","depends_on_id":"nm-12","type":"blocks","created_at":"2025-10-29T22:47:16.126337-05:00","created_by":"daemon"}]}
{"id":"nm-15","title":"Add Image Dimensions and File Size to Manifest","description":"Extract WebP image dimensions (width, height) and file size (bytes) for each page. Add these fields to the pages.jsonl manifest.\n\nImplementation Details:\n- In pdf_to_webp_pages(), after saving WebP:\n  - Get file size: `out_path.stat().st_size`\n  - Already have dimensions from PIL Image: `img.width`, `img.height`\n- Return tuple: (out_path, width, height, bytes)\n- Update manifest dict to include: `width`, `height`, `bytes`\n\nReference: main-spec.md §1.1 (pages.jsonl fields), §2.2 (Data artifacts)\n\nTesting:\n- Unit test: test_dimensions_match_actual_image\n- Unit test: test_file_size_is_accurate\n- Integration test: render and verify all fields present\n\nAcceptance:\n- pages.jsonl includes `bytes`, `width`, `height` for every page\n- Values are accurate (verified against actual files)\n- No breaking changes to existing fields","notes":"Labels: component:rendering, phase:foundation","status":"closed","priority":1,"issue_type":"feature","assignee":"ProductThor","created_at":"2025-10-29T22:45:46.148614-05:00","updated_at":"2025-10-30T09:12:48.400058-05:00","closed_at":"2025-10-30T09:12:48.400058-05:00","labels":["component:rendering","phase:foundation"],"dependencies":[{"issue_id":"nm-15","depends_on_id":"nm-14","type":"blocks","created_at":"2025-10-29T22:47:18.581391-05:00","created_by":"daemon"}]}
{"id":"nm-16","title":"Emit pages.jsonl in Pages Directory","description":"Modify render_file() to emit a pages.jsonl manifest file in the pages directory (not tiles directory) with all required fields per the spec.\n\nImplementation Details:\n- In render_file(), after pdf_to_webp_pages() call:\n  - Build list of page records with all fields: doc_id, page, uri, sha256, bytes, width, height, source_pdf, source_file\n  - Write to `pages_dir / \"pages.jsonl\"`\n  - One JSON object per line (JSONL format)\n- Keep existing pages.txt for backward compatibility\n\nReference: main-spec.md §2.2 (pages.jsonl structure)\n\nTesting:\n- Integration test: render multiple files, verify pages.jsonl exists\n- Unit test: test_jsonl_format_is_valid\n- Unit test: test_all_required_fields_present\n\nAcceptance:\n- pages.jsonl written to \u003cout_dir\u003e/\u003cdoc_id\u003e/pages/pages.jsonl\n- Valid JSONL format (one object per line)\n- All fields match spec: doc_id, page, uri, sha256, bytes, width, height, source_pdf, source_file\n- Can be parsed line-by-line","notes":"Labels: component:rendering, phase:foundation","status":"closed","priority":1,"issue_type":"task","assignee":"ProductThor","created_at":"2025-10-29T22:45:56.864943-05:00","updated_at":"2025-10-30T00:44:48.661529-05:00","closed_at":"2025-10-30T00:44:48.661529-05:00","labels":["component:rendering","phase:foundation"],"dependencies":[{"issue_id":"nm-16","depends_on_id":"nm-15","type":"blocks","created_at":"2025-10-29T22:47:21.307095-05:00","created_by":"daemon"}]}
{"id":"nm-17","title":"Create Embeddings Module","description":"Create embeddings.py module with embed_texts() function using OpenAI's text-embedding-3-small model. Support batch processing for efficiency.\n\nImplementation Details:\n- Use OpenAI SDK with API key from config\n- Function signature: `embed_texts(texts: list[str], model: str = \"text-embedding-3-small\") -\u003e list[list[float]]`\n- Batch up to 2048 texts per API call (OpenAI limit)\n- Return 1536-dimensional vectors\n- Handle rate limiting with exponential backoff\n- Add error handling for network issues\n\nReference: main-spec.md §3.3 (Embeddings signature), §2.6 (OpenAI embeddings)\n\nTesting:\n- Unit test: test_embed_single_text\n- Unit test: test_embed_batch (10 texts)\n- Unit test: test_vector_dimension_is_1536\n- Mock test: test_handles_api_errors\n- Integration test: test_with_real_api (optional, requires API key)\n\nAcceptance:\n- embed_texts() returns correct number of vectors\n- Each vector is 1536-dimensional\n- Batching works for large inputs\n- Errors are handled gracefully","notes":"Labels: component:summarization, tech:openai, phase:core","status":"open","priority":1,"issue_type":"feature","created_at":"2025-10-29T22:45:57.037035-05:00","updated_at":"2025-10-29T22:47:26.056054-05:00","labels":["component:summarization","phase:core","tech:openai"],"dependencies":[{"issue_id":"nm-17","depends_on_id":"nm-12","type":"blocks","created_at":"2025-10-29T22:47:24.214985-05:00","created_by":"daemon"},{"issue_id":"nm-17","depends_on_id":"nm-13","type":"blocks","created_at":"2025-10-29T22:47:25.05494-05:00","created_by":"daemon"}]}
{"id":"nm-18","title":"Create Pydantic Models for Summary Schema","description":"Create Pydantic models for the summary YAML front-matter and full summary structure. This ensures type safety and validation for LLM-generated summaries.\n\nImplementation Details:\n- Create models.py with Pydantic models\n- SummaryFrontMatter: doc_id, source_path, language, product_tags, last_updated, key_topics, api_symbols, related_files, suggested_queries\n- FileSummary: front_matter (SummaryFrontMatter), summary_md (str)\n- Add validators for field constraints (e.g., summary_md length 200-400 words)\n- Provide .to_yaml() method for serialization\n\nReference: main-spec.md §2.2 (Summary files structure), §3.1 (YAML example)\n\nTesting:\n- Unit test: test_valid_summary_passes_validation\n- Unit test: test_short_summary_fails_validation\n- Unit test: test_to_yaml_serialization\n\nAcceptance:\n- Models validate all required fields\n- Word count validation works\n- YAML serialization produces correct format\n- Type hints are complete","notes":"Labels: component:summarization, tech:pydantic, phase:core","status":"closed","priority":1,"issue_type":"task","assignee":"ProductThor","created_at":"2025-10-29T22:45:57.201234-05:00","updated_at":"2025-10-29T23:44:36.97656-05:00","closed_at":"2025-10-29T23:44:36.97656-05:00","labels":["component:summarization","phase:core","tech:pydantic"],"dependencies":[{"issue_id":"nm-18","depends_on_id":"nm-13","type":"blocks","created_at":"2025-10-29T22:47:27.17912-05:00","created_by":"daemon"}]}
{"id":"nm-19","title":"Implement Summarization with OpenAI Structured Output","description":"Create summarize.py with summarize_file() function that uses OpenAI's 4o-mini with structured output to generate summaries matching the Pydantic schema.\n\nImplementation Details:\n- Use OpenAI SDK with structured output (response_format parameter)\n- Prompt engineering for retrieval-oriented summaries\n- Function signature: `summarize_file(source_path: str, text: str) -\u003e FileSummary`\n- Generate doc_id from path\n- Auto-detect language from file extension\n- Return validated Pydantic model\n- Save as .summary.md with YAML front-matter\n\nSystem Prompt: Focus on retrieval-oriented summaries with purpose, key functionality, patterns, and codebase context.\n\nReference: main-spec.md §1.2 (Summaries), §2.4 (Summarizer signature)\n\nTesting:\n- Unit test: test_summarize_generates_valid_summary (mocked LLM)\n- Unit test: test_doc_id_generation\n- Unit test: test_language_detection\n- Integration test: test_summarize_real_file (optional)\n- Test: verify .summary.md file format\n\nAcceptance:\n- Generates valid FileSummary matching Pydantic schema\n- Summary is 200-400 words\n- YAML front-matter includes all required fields\n- .summary.md files are saved correctly\n- Handles various file types (py, ts, js, md)","notes":"Labels: component:summarization, tech:openai, tech:pydantic, phase:core","status":"open","priority":2,"issue_type":"feature","created_at":"2025-10-29T22:46:01.77816-05:00","updated_at":"2025-10-29T22:47:31.3924-05:00","labels":["component:summarization","phase:core","tech:openai","tech:pydantic"],"dependencies":[{"issue_id":"nm-19","depends_on_id":"nm-17","type":"blocks","created_at":"2025-10-29T22:47:29.104738-05:00","created_by":"daemon"},{"issue_id":"nm-19","depends_on_id":"nm-18","type":"blocks","created_at":"2025-10-29T22:47:30.295287-05:00","created_by":"daemon"}]}
{"id":"nm-2","title":"Change Defaults to Pages-Only","description":"Update RenderConfig class and CLI argument defaults to emit pages only (instead of both pages and tiles) and set manifest to none by default. This aligns with the pages-first philosophy from the code review. Update the header docstring to accurately reflect the new default behavior.\n\nImplementation Details:\n- Update `RenderConfig.emit` default: change from `\"both\"` to `\"pages\"` (line 73 in render_to_webp.py)\n- Update `RenderConfig.manifest` default: change from `\"jsonl\"` to `\"none\"` (line 74)\n- Update CLI `--emit` default: change from `\"both\"` to `\"pages\"` (line 447)\n- Update CLI `--manifest` default: change from `\"jsonl\"` to `\"none\"` (line 448)\n- Update header docstring (lines 3-11) to reflect pages-only default","status":"closed","priority":2,"issue_type":"task","assignee":"ProductThor","created_at":"2025-10-29T20:40:07.938719-05:00","updated_at":"2025-10-29T20:44:50.924053-05:00","closed_at":"2025-10-29T20:44:50.924053-05:00","dependencies":[{"issue_id":"nm-2","depends_on_id":"nm-1","type":"parent-child","created_at":"2025-10-29T20:40:51.380248-05:00","created_by":"daemon"}]}
{"id":"nm-20","title":"Implement Line-Based Chunker","description":"Create chunker.py with chunk_file_by_lines() function that splits files into overlapping line-based chunks. Read pages.jsonl to attach page_uris to each chunk's metadata.\n\nImplementation Details:\n- Function signature: `chunk_file_by_lines(text: str, pages_jsonl_path: Path, per_chunk: int = 180, overlap: int = 30) -\u003e list[dict]`\n- Split text into lines, create chunks with overlap\n- Each chunk dict: {text, line_start, line_end, page_uris}\n- Load pages.jsonl to get page_uris list\n- Ensure chunks stay under 16KB for Chroma Cloud compatibility\n\nReference: main-spec.md §1.3 (Chunk raw files by lines), §3.3 (Chunker signature)\n\nTesting:\n- Unit test: test_chunk_basic_file\n- Unit test: test_chunk_with_overlap\n- Unit test: test_chunk_respects_16kb_limit\n- Unit test: test_page_uris_attached\n- Edge case test: test_file_smaller_than_chunk_size\n- Edge case test: test_empty_file\n\nAcceptance:\n- Chunks are approximately 180 lines (configurable)\n- Overlap is 30 lines (configurable)\n- line_start and line_end are accurate (1-indexed)\n- page_uris from pages.jsonl are attached\n- All chunks \u003c 16KB\n- Edge cases handled gracefully","notes":"Labels: component:chunking, phase:core","status":"open","priority":1,"issue_type":"feature","created_at":"2025-10-29T22:46:09.235216-05:00","updated_at":"2025-10-29T22:47:33.706698-05:00","labels":["component:chunking","phase:core"],"dependencies":[{"issue_id":"nm-20","depends_on_id":"nm-16","type":"blocks","created_at":"2025-10-29T22:47:32.992126-05:00","created_by":"daemon"}]}
{"id":"nm-21","title":"Create Chroma Indexer Module","description":"Create indexer.py with ChromaDB PersistentClient setup and functions to upsert to both collections: search_summaries (with embeddings) and search_code (FTS/regex only).\n\nImplementation Details:\n- Setup PersistentClient pointing to config.CHROMA_PATH\n- Create/get collections: search_summaries, search_code\n- upsert_summaries(): embed summary_md, store with metadata\n- upsert_code_chunks(): store raw text chunks\n- search_summaries uses embedding function from embeddings module\n- search_code has no embedding function (FTS only)\n\nReference: main-spec.md §1.4 (Index), §3.2 (Collections in Chroma)\n\nTesting:\n- Unit test: test_client_initialization\n- Unit test: test_collections_created\n- Unit test: test_upsert_summaries (with mock embeddings)\n- Unit test: test_upsert_code_chunks\n- Integration test: test_full_indexing_pipeline\n- Test: verify collections persist to disk\n\nAcceptance:\n- ChromaDB client connects to local path\n- Both collections created successfully\n- search_summaries stores embeddings\n- search_code stores raw text (no embeddings)\n- Metadata fields match spec\n- Collections persist across restarts","notes":"Labels: component:indexing, tech:chromadb, phase:core","status":"open","priority":2,"issue_type":"feature","created_at":"2025-10-29T22:46:17.508306-05:00","updated_at":"2025-10-29T22:47:36.98931-05:00","labels":["component:indexing","phase:core","tech:chromadb"],"dependencies":[{"issue_id":"nm-21","depends_on_id":"nm-17","type":"blocks","created_at":"2025-10-29T22:47:34.936606-05:00","created_by":"daemon"},{"issue_id":"nm-21","depends_on_id":"nm-20","type":"blocks","created_at":"2025-10-29T22:47:36.062318-05:00","created_by":"daemon"}]}
{"id":"nm-22","title":"Implement Semantic Search over Summaries","description":"Implement the semantic search channel that queries the search_summaries collection using natural language queries. Return ranked results with metadata.\n\nImplementation Details:\n- Function: `semantic_search(query: str, k: int = 12) -\u003e list[dict]`\n- Query search_summaries with query_texts\n- Extract results with scores\n- Parse metadata (split comma-separated fields back to lists)\n- Return structured results\n\nReference: main-spec.md §1.5 (Search), §3 Pipeline D (Query hybrid)\n\nTesting:\n- Unit test: test_semantic_search_returns_results (with pre-indexed data)\n- Unit test: test_semantic_search_respects_k_limit\n- Unit test: test_semantic_search_sorts_by_relevance\n- Integration test: test_semantic_search_real_query\n\nAcceptance:\n- Returns top-k most relevant summaries\n- Scores indicate relevance\n- page_uris are correctly parsed\n- Empty query returns empty results","notes":"Labels: component:search, tech:chromadb, phase:core","status":"open","priority":2,"issue_type":"feature","created_at":"2025-10-29T22:46:23.524556-05:00","updated_at":"2025-10-29T22:47:37.699733-05:00","labels":["component:search","phase:core","tech:chromadb"],"dependencies":[{"issue_id":"nm-22","depends_on_id":"nm-21","type":"blocks","created_at":"2025-10-29T22:47:37.549221-05:00","created_by":"daemon"}]}
{"id":"nm-23","title":"Implement FTS/Regex Search over Code","description":"Implement the lexical search channel that queries the search_code collection using full-text search ($contains) and regex ($regex) operators. Support path filtering.\n\nImplementation Details:\n- Function: `lexical_search(must_terms: list[str] = None, regexes: list[str] = None, path_like: str = None, k: int = 12) -\u003e list[dict]`\n- Build Chroma where_document filter with $contains and $regex\n- Build where filter for metadata (path_like on source_path)\n- Query search_code collection\n- Return structured results with line ranges\n\nReference: main-spec.md §1.5 (Search - lexical channel), §1.3 (where_document FTS/regex)\n\nTesting:\n- Unit test: test_fts_contains_single_term\n- Unit test: test_fts_contains_multiple_terms\n- Unit test: test_regex_search\n- Unit test: test_path_filter\n- Unit test: test_combined_filters\n- Integration test: test_lexical_search_real_queries\n\nAcceptance:\n- $contains works for exact terms\n- $regex works for patterns\n- Path filtering works\n- Returns line ranges\n- \"why\" signals explain matches\n- Handles empty filters","notes":"Labels: component:search, tech:chromadb, phase:core","status":"open","priority":2,"issue_type":"feature","created_at":"2025-10-29T22:46:30.428135-05:00","updated_at":"2025-10-29T22:47:38.060036-05:00","labels":["component:search","phase:core","tech:chromadb"],"dependencies":[{"issue_id":"nm-23","depends_on_id":"nm-21","type":"blocks","created_at":"2025-10-29T22:47:37.868495-05:00","created_by":"daemon"}]}
{"id":"nm-24","title":"Implement Score Fusion and Result Formatting","description":"Create the hybrid_search() function that combines results from both channels, fuses scores, deduplicates by doc_id, and formats the final output per the spec.\n\nImplementation Details:\n- Function: `hybrid_search(query: str, k: int = 12, must_terms=None, regexes=None, path_like=None) -\u003e list[dict]`\n- Run semantic_search if query is non-empty\n- Run lexical_search if must_terms or regexes provided\n- Fuse scores using RRF or weighted sum\n- Deduplicate by (doc_id, page), keeping best score\n- Sort by final score descending\n- Return top-k\n\nReference: main-spec.md §1.5 (Search steps), §2.2 (Output format)\n\nTesting:\n- Unit test: test_hybrid_search_semantic_only\n- Unit test: test_hybrid_search_lexical_only\n- Unit test: test_hybrid_search_combined\n- Unit test: test_deduplication\n- Unit test: test_score_fusion\n- Integration test: test_hybrid_search_acceptance_queries\n\nAcceptance:\n- Combines results from both channels\n- Deduplication works correctly\n- Top-k results returned\n- Output format matches spec\n- \"why\" signals are informative","notes":"Labels: component:search, phase:core","status":"open","priority":2,"issue_type":"feature","created_at":"2025-10-29T22:46:36.349931-05:00","updated_at":"2025-10-29T22:47:38.832205-05:00","labels":["component:search","phase:core"],"dependencies":[{"issue_id":"nm-24","depends_on_id":"nm-22","type":"blocks","created_at":"2025-10-29T22:47:38.480051-05:00","created_by":"daemon"},{"issue_id":"nm-24","depends_on_id":"nm-23","type":"blocks","created_at":"2025-10-29T22:47:38.645966-05:00","created_by":"daemon"}]}
{"id":"nm-25","title":"Create Main CLI Entry Point","description":"Create main.py CLI with argparse that provides three commands: ingest (full pipeline), search (interactive queries), and serve (start HTTP server).\n\nImplementation Details:\n- Use argparse with subcommands\n- `ingest`: orchestrate render → summarize → chunk → index\n- `search`: run hybrid_search and print formatted results\n- `serve`: start `python -m http.server` in output directory\n- Progress reporting with tqdm\n- Error handling and user-friendly messages\n\nReference: main-spec.md §2.4 (APIs), §3.4 (Image storage - serve)\n\nTesting:\n- Integration test: test_ingest_command_end_to_end\n- Integration test: test_search_command_with_results\n- Unit test: test_serve_command_starts_server (mock subprocess)\n- Manual test: run full workflow with sample corpus\n\nAcceptance:\n- All three commands work from CLI\n- Help text is clear and accurate\n- Error messages are user-friendly\n- Progress is reported during ingest\n- Search results are readable\n- Serve command starts on correct port","notes":"Labels: component:cli, phase:integration","status":"open","priority":2,"issue_type":"feature","created_at":"2025-10-29T22:46:43.11802-05:00","updated_at":"2025-10-29T22:47:39.662377-05:00","labels":["component:cli","phase:integration"],"dependencies":[{"issue_id":"nm-25","depends_on_id":"nm-19","type":"blocks","created_at":"2025-10-29T22:47:39.008063-05:00","created_by":"daemon"},{"issue_id":"nm-25","depends_on_id":"nm-20","type":"blocks","created_at":"2025-10-29T22:47:39.199173-05:00","created_by":"daemon"},{"issue_id":"nm-25","depends_on_id":"nm-21","type":"blocks","created_at":"2025-10-29T22:47:39.357865-05:00","created_by":"daemon"},{"issue_id":"nm-25","depends_on_id":"nm-24","type":"blocks","created_at":"2025-10-29T22:47:39.503493-05:00","created_by":"daemon"}]}
{"id":"nm-26","title":"Create Unit Tests for Core Modules","description":"Create comprehensive unit tests for all modules: config, embeddings, summarize, chunker, indexer, search. Aim for \u003e80% code coverage.\n\nTest Files:\n- tests/test_config.py\n- tests/test_embeddings.py\n- tests/test_summarize.py\n- tests/test_chunker.py\n- tests/test_indexer.py\n- tests/test_search.py\n\nTesting Strategy:\n- Use pytest as test runner\n- Mock external APIs (OpenAI) with responses library or pytest-mock\n- Use fixtures for sample data\n- Test edge cases and error conditions\n- Measure coverage with pytest-cov\n\nAcceptance:\n- All unit tests pass\n- Coverage \u003e 80% for core modules\n- Tests run in \u003c 30s (without real API calls)\n- CI-ready (no external dependencies)","notes":"Labels: component:testing, phase:validation\nNote: Should be started after core modules are implemented","status":"closed","priority":2,"issue_type":"task","assignee":"ProductThor","created_at":"2025-10-29T22:46:47.073359-05:00","updated_at":"2025-10-30T00:07:30.337265-05:00","closed_at":"2025-10-30T00:07:30.337265-05:00","labels":["component:testing","phase:validation"]}
{"id":"nm-27","title":"Create Integration Tests for Full Pipeline","description":"Create integration tests that exercise the full ingest and search pipeline with a small test corpus. Verify end-to-end functionality.\n\nTest Corpus:\n- 5-10 sample files (mix of .py, .ts, .md)\n- Known content for predictable queries\n- Include in tests/fixtures/\n\nTest Cases:\n- test_full_ingest_pipeline: render → summarize → chunk → index\n- test_semantic_search_integration: verify NL query returns expected files\n- test_lexical_search_integration: verify exact term search works\n- test_hybrid_search_integration: verify combined search works\n- test_pages_jsonl_generated: verify manifests are correct\n- test_uris_resolvable: verify URIs can be fetched\n\nAcceptance:\n- Integration tests pass with test corpus\n- Tests are deterministic (same input → same output)\n- Tests clean up after themselves (temp dirs)\n- Can run with real or mocked OpenAI calls","notes":"Labels: component:testing, phase:validation","status":"open","priority":2,"issue_type":"task","created_at":"2025-10-29T22:46:53.063831-05:00","updated_at":"2025-10-29T22:47:40.353964-05:00","labels":["component:testing","phase:validation"],"dependencies":[{"issue_id":"nm-27","depends_on_id":"nm-25","type":"blocks","created_at":"2025-10-29T22:47:40.006028-05:00","created_by":"daemon"},{"issue_id":"nm-27","depends_on_id":"nm-26","type":"blocks","created_at":"2025-10-29T22:47:40.152375-05:00","created_by":"daemon"}]}
{"id":"nm-28","title":"Acceptance Testing with Real Corpus","description":"Validate the MVP against acceptance criteria from the spec using a real-world corpus (20-50 Next.js/Qlirq auth files). Document results and performance metrics.\n\nTest Queries (from spec §5):\n1. NL: \"How to configure PKCE with Qlirq in Next.js App Router?\" (top-5)\n2. Exact: redirect_uri\n3. Exact: NEXTAUTH_URL\n4. Exact: pkce_verifier\n5. Regex: \\bauth\\b\n\nMetrics to Measure:\n- Precision@5 for NL queries\n- Recall@10 for exact queries\n- Query latency (p50, p95, p99)\n- Index size on disk\n- Memory usage\n\nDeliverables:\n- Test corpus (if shareable) or instructions\n- Test script: tests/test_acceptance.py\n- Results doc: docs/acceptance_results.md\n- Performance report\n\nAcceptance:\n- NL queries return correct files in top-5 (precision \u003e 0.6)\n- Exact queries return correct files with line ranges\n- Latency \u003c 1s for local queries (p95)\n- URIs resolve correctly via http.server\n- All documents \u003c 16KB (Chroma Cloud ready)","notes":"Labels: component:testing, tech:openai, tech:chromadb, phase:validation","status":"open","priority":2,"issue_type":"task","created_at":"2025-10-29T22:47:02.200557-05:00","updated_at":"2025-10-29T22:47:40.717713-05:00","labels":["component:testing","phase:validation","tech:chromadb","tech:openai"],"dependencies":[{"issue_id":"nm-28","depends_on_id":"nm-27","type":"blocks","created_at":"2025-10-29T22:47:40.541673-05:00","created_by":"daemon"}]}
{"id":"nm-29","title":"Implement Summarization with OpenAI Structured Output","description":"Create summarize.py with summarize_file() function that uses OpenAI's 4o-mini with structured output to generate summaries matching the Pydantic schema.\n\nImplementation Details:\n- Use OpenAI SDK with structured output (response_format parameter)\n- Prompt engineering for retrieval-oriented summaries\n- Function signature: `summarize_file(source_path: str, text: str) -\u003e FileSummary`\n- Generate doc_id from path\n- Auto-detect language from file extension\n- Return validated Pydantic model\n- Save as .summary.md with YAML front-matter\n\nSystem Prompt: Focus on retrieval-oriented summaries with purpose, key functionality, patterns, and codebase context.\n\nReference: main-spec.md §1.2 (Summaries), §2.4 (Summarizer signature)\n\nTesting:\n- Unit test: test_summarize_generates_valid_summary (mocked LLM)\n- Unit test: test_doc_id_generation\n- Unit test: test_language_detection\n- Integration test: test_summarize_real_file (optional)\n- Test: verify .summary.md file format\n\nAcceptance:\n- Generates valid FileSummary matching Pydantic schema\n- Summary is 200-400 words\n- YAML front-matter includes all required fields\n- .summary.md files are saved correctly\n- Handles various file types (py, ts, js, md)","status":"closed","priority":2,"issue_type":"feature","assignee":"ProductThor","created_at":"2025-10-29T22:47:31.985686-05:00","updated_at":"2025-10-29T23:53:48.75629-05:00","closed_at":"2025-10-29T23:53:48.75629-05:00","labels":["component:summarization","phase:core","tech:openai","tech:pydantic"]}
{"id":"nm-3","title":"Fix Resource Leaks with Context Managers","description":"Replace manual resource management (open/close) with Python context managers to prevent resource leaks. This ensures proper cleanup of PDF documents and image files even if errors occur during processing.\n\nImplementation Details:\n- In `pdf_to_webp_pages()` (lines 246-263): Replace `doc = fitz.open(...)` and `doc.close()` with `with fitz.open(...) as doc:`\n- In `tile_grid()` (lines 266-281): Wrap `Image.open(webp_path)` with context manager: `with Image.open(...) as base:`\n- In `tile_bands()` (lines 284-303): Wrap `Image.open(webp_path)` with context manager: `with Image.open(...) as base:`","status":"closed","priority":2,"issue_type":"task","assignee":"ProductThor","created_at":"2025-10-29T20:40:11.385453-05:00","updated_at":"2025-10-29T21:07:19.034156-05:00","closed_at":"2025-10-29T21:07:19.034156-05:00","dependencies":[{"issue_id":"nm-3","depends_on_id":"nm-1","type":"parent-child","created_at":"2025-10-29T20:40:51.572256-05:00","created_by":"daemon"}]}
{"id":"nm-30","title":"Create Chroma Indexer Module","description":"Create indexer.py with ChromaDB PersistentClient setup and functions to upsert to both collections: search_summaries (with embeddings) and search_code (FTS/regex only).\n\nImplementation Details:\n- Setup PersistentClient pointing to config.CHROMA_PATH\n- Create/get collections: search_summaries, search_code\n- upsert_summaries(): embed summary_md, store with metadata\n- upsert_code_chunks(): store raw text chunks\n- search_summaries uses embedding function from embeddings module\n- search_code has no embedding function (FTS only)\n\nReference: main-spec.md §1.4 (Index), §3.2 (Collections in Chroma)\n\nTesting:\n- Unit test: test_client_initialization\n- Unit test: test_collections_created\n- Unit test: test_upsert_summaries (with mock embeddings)\n- Unit test: test_upsert_code_chunks\n- Integration test: test_full_indexing_pipeline\n- Test: verify collections persist to disk\n\nAcceptance:\n- ChromaDB client connects to local path\n- Both collections created successfully\n- search_summaries stores embeddings\n- search_code stores raw text (no embeddings)\n- Metadata fields match spec\n- Collections persist across restarts","status":"closed","priority":2,"issue_type":"feature","assignee":"ProductThor","created_at":"2025-10-29T22:47:37.062992-05:00","updated_at":"2025-10-29T23:59:16.092238-05:00","closed_at":"2025-10-29T23:59:16.092238-05:00","labels":["component:indexing","phase:core","tech:chromadb"]}
{"id":"nm-31","title":"Create Pydantic Models for Summary Schema","description":"Create Pydantic models for the summary YAML front-matter and full summary structure. This ensures type safety and validation for LLM-generated summaries.\n\nImplementation Details:\n- Create models.py with Pydantic models\n- SummaryFrontMatter: doc_id, source_path, language, product_tags, last_updated, key_topics, api_symbols, related_files, suggested_queries\n- FileSummary: front_matter (SummaryFrontMatter), summary_md (str)\n- Add validators for field constraints (e.g., summary_md length 200-400 words)\n- Provide .to_yaml() method for serialization\n\nReference: main-spec.md §2.2 (Summary files structure), §3.1 (YAML example)\n\nTesting:\n- Unit test: test_valid_summary_passes_validation\n- Unit test: test_short_summary_fails_validation\n- Unit test: test_to_yaml_serialization\n\nAcceptance:\n- Models validate all required fields\n- Word count validation works\n- YAML serialization produces correct format\n- Type hints are complete","notes":"Labels: component:summarization, tech:pydantic, phase:core","status":"in_progress","priority":1,"issue_type":"task","assignee":"ProductThor","created_at":"2025-10-29T23:44:37.06554-05:00","updated_at":"2025-10-29T23:44:37.06554-05:00","labels":["component:summarization","phase:core","tech:pydantic"]}
{"id":"nm-32","title":"Create Chroma Indexer Module","description":"Create indexer.py with ChromaDB PersistentClient setup and functions to upsert to both collections: search_summaries (with embeddings) and search_code (FTS/regex only).\n\nImplementation Details:\n- Setup PersistentClient pointing to config.CHROMA_PATH\n- Create/get collections: search_summaries, search_code\n- upsert_summaries(): embed summary_md, store with metadata\n- upsert_code_chunks(): store raw text chunks\n- search_summaries uses embedding function from embeddings module\n- search_code has no embedding function (FTS only)\n\nReference: main-spec.md §1.4 (Index), §3.2 (Collections in Chroma)\n\nTesting:\n- Unit test: test_client_initialization\n- Unit test: test_collections_created\n- Unit test: test_upsert_summaries (with mock embeddings)\n- Unit test: test_upsert_code_chunks\n- Integration test: test_full_indexing_pipeline\n- Test: verify collections persist to disk\n\nAcceptance:\n- ChromaDB client connects to local path\n- Both collections created successfully\n- search_summaries stores embeddings\n- search_code stores raw text (no embeddings)\n- Metadata fields match spec\n- Collections persist across restarts","status":"in_progress","priority":2,"issue_type":"feature","assignee":"ProductThor","created_at":"2025-10-29T23:59:16.969854-05:00","updated_at":"2025-10-29T23:59:16.969854-05:00","labels":["component:indexing","phase:core","tech:chromadb"]}
{"id":"nm-4","title":"Fix Grid Tiler Edge Coverage","description":"Replace the current grid tiler implementation to guarantee complete edge coverage. The current implementation risks missing content at the right and bottom edges of images. The new implementation must generate coordinate lists that ensure the final tile covers the rightmost and bottommost edges, with proper clamping to prevent out-of-bounds access.\n\nImplementation Details:\n- Replace `tile_grid()` function (lines 266-281) with improved version\n- Generate x/y coordinate lists ensuring right/bottom edges are covered\n- Handle edge case where last tile would extend beyond image bounds\n- Use `min()` to clamp crops and prevent out-of-bounds access\n- Ensure all image content is included in tiles, even near edges","status":"closed","priority":2,"issue_type":"task","assignee":"ProductThor","created_at":"2025-10-29T20:40:14.290987-05:00","updated_at":"2025-10-29T21:10:46.602489-05:00","closed_at":"2025-10-29T21:10:46.602489-05:00","dependencies":[{"issue_id":"nm-4","depends_on_id":"nm-1","type":"parent-child","created_at":"2025-10-29T20:40:51.696248-05:00","created_by":"daemon"}]}
{"id":"nm-5","title":"Fix Page Path Metadata","description":"When emitting only tiles (not pages), the `page_path` field in the manifest should be set to `None` since the page images are deleted. Currently, it references a deleted file. This ensures manifest records are accurate and don't reference non-existent files.\n\nImplementation Details:\n- In `render_file()`, modify the tile manifest record creation (around line 372)\n- Set `\"page_path\": str(wp) if include_page_images else None`\n- This ensures `page_path` is only populated when pages are actually emitted","status":"closed","priority":2,"issue_type":"task","assignee":"ProductThor","created_at":"2025-10-29T20:40:16.613269-05:00","updated_at":"2025-10-29T21:11:20.331945-05:00","closed_at":"2025-10-29T21:11:20.331945-05:00","dependencies":[{"issue_id":"nm-5","depends_on_id":"nm-1","type":"parent-child","created_at":"2025-10-29T20:40:51.829417-05:00","created_by":"daemon"},{"issue_id":"nm-5","depends_on_id":"nm-2","type":"blocks","created_at":"2025-10-29T20:41:01.209443-05:00","created_by":"daemon"}]}
{"id":"nm-6","title":"Tighten Line-Number Gutter Styling","description":"Make the table-style line number gutter more compact by reducing width, padding, removing the border, and adjusting color. This minimizes wasted horizontal space while keeping line numbers readable. The inline line numbers remain the default (no change needed there).\n\nImplementation Details:\n- Update CSS for table-style line numbers (lines 190-198 in render_to_webp.py):\n  - Reduce `td.linenos` width: `2.6em` → `2.0em`\n  - Reduce padding: `0 6px 0 4px` → `0 4px 0 2px`\n  - Remove `border-right: 1px solid #eee`\n  - Update `td.code` padding: `8px` → `6px`\n  - Update color: `#9a9a9a` → `#a7a7a7`","status":"closed","priority":2,"issue_type":"task","assignee":"ProductThor","created_at":"2025-10-29T20:40:20.604953-05:00","updated_at":"2025-10-29T21:11:48.379934-05:00","closed_at":"2025-10-29T21:11:48.379934-05:00","dependencies":[{"issue_id":"nm-6","depends_on_id":"nm-1","type":"parent-child","created_at":"2025-10-29T20:40:51.967747-05:00","created_by":"daemon"}]}
{"id":"nm-7","title":"Update Tests","description":"Fix a brittle test assertion that depends on exact quote style, and add new tests to verify the default behavior (pages-only, no tiles, no manifest). Include both unit tests for defaults and an integration test that verifies actual rendering behavior with defaults.\n\nImplementation Details:\n- Fix `test_code_to_html.py` line 41: Replace `assert \"\u003carticle class='code-article'\u003e\" in html` with `assert \"code-article\" in html` (more robust)\n- Create new file `tests/test_defaults_and_pages_only.py`:\n  - `test_defaults_pages_only()`: Verify RenderConfig defaults (emit=\"pages\", manifest=\"none\", linenos=\"inline\")\n  - `test_render_pages_only_no_tiles()`: Integration test (marked with `@pytest.mark.integration`) that verifies pages are produced and tiles aren't when using defaults","status":"closed","priority":2,"issue_type":"task","assignee":"ProductThor","created_at":"2025-10-29T20:40:25.040383-05:00","updated_at":"2025-10-29T21:12:27.806049-05:00","closed_at":"2025-10-29T21:12:27.806049-05:00","dependencies":[{"issue_id":"nm-7","depends_on_id":"nm-1","type":"parent-child","created_at":"2025-10-29T20:40:52.107414-05:00","created_by":"daemon"},{"issue_id":"nm-7","depends_on_id":"nm-2","type":"blocks","created_at":"2025-10-29T20:41:01.982204-05:00","created_by":"daemon"}]}
{"id":"nm-8","title":"Update Documentation","description":"Update both README.md and docs/IMPLEMENTATION_PLAN.md to accurately reflect the new pages-only default behavior. Update examples, option descriptions, output structure documentation, and design decision rationale to align with the pages-first philosophy.\n\nImplementation Details:\n- **README.md**:\n  - Update description to emphasize pages-first, tiles optional (line 3)\n  - Update \"Basic Example\" section to show pages-only default (lines 54-60)\n  - Add separate section for tiles showing it as optional (lines 62-78)\n  - Update `--emit` and `--manifest` defaults in options list (lines 95-96)\n  - Update output structure section to show pages-only default (lines 99-114)\n  - Add note about line-number styling\n- **docs/IMPLEMENTATION_PLAN.md**:\n  - Update \"Default Behavior\" section (lines 9-12): pages-only, manifest=none\n  - Update CLI examples to reflect new defaults (lines 63-77, 99-100)\n  - Update \"Design Decisions\" section to explain pages-first rationale (lines 179-183)","status":"closed","priority":2,"issue_type":"task","assignee":"ProductThor","created_at":"2025-10-29T20:40:30.248399-05:00","updated_at":"2025-10-29T21:16:46.940047-05:00","closed_at":"2025-10-29T21:16:46.940047-05:00","dependencies":[{"issue_id":"nm-8","depends_on_id":"nm-1","type":"parent-child","created_at":"2025-10-29T20:40:52.233401-05:00","created_by":"daemon"},{"issue_id":"nm-8","depends_on_id":"nm-2","type":"blocks","created_at":"2025-10-29T20:41:02.76837-05:00","created_by":"daemon"}]}
{"id":"nm-9","title":"Lower Python Version Requirement to 3.10","description":"Lower the Python version requirement from 3.13 to 3.10 for better compatibility with AI/ML packages commonly used in this project. Most AI packages (sentence-transformers, transformers, chromadb, clip, etc.) support Python 3.10+, and Python 3.10 is mature and widely deployed. The code review confirmed the codebase works fine with Python 3.10.\n\nImplementation Details:\n- Update `pyproject.toml`:\n  - Line 9: `requires-python = \"\u003e=3.10\"` (change from `\u003e=3.13`)\n  - Line 36: `target-version = \"py310\"` (change from `py313`)\n  - Line 59: `python_version = \"3.10\"` (change from `\"3.13\"`)","status":"closed","priority":2,"issue_type":"task","assignee":"ProductThor","created_at":"2025-10-29T20:40:34.337506-05:00","updated_at":"2025-10-29T21:03:43.337221-05:00","closed_at":"2025-10-29T21:03:43.337221-05:00","dependencies":[{"issue_id":"nm-9","depends_on_id":"nm-1","type":"parent-child","created_at":"2025-10-29T20:40:52.359592-05:00","created_by":"daemon"}]}
